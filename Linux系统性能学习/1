
有监控的情况下，首先去看看监控大盘，看看有没有异常报警，如果初期还没有监控的情况我会按照下面步骤去看看系统层面有没有异常
1、我首先会去看看系统的平均负载，使用top或者htop命令查看,平均负载体现的是系统的一个整体情况，他应该是cpu、内存、磁盘性能的一个综合，一般是平均负载的值大于机器cpu的核数，这时候说明机器资源已经紧张了
2、平均负载高了以后，接下来就要看看具体是什么资源导致，我首先会在top中看cpu每个核的使用情况，如果占比很高，那瓶颈应该是cpu,接下来就要看看是什么进程导致的
3、如果cpu没有问题，那接下来我会去看内存，首先是用free去查看内存的是用情况，但不直接看他剩余了多少，还要结合看看cache和buffer，然后再看看具体是什么进程占用了过高的内存，我也是是用top去排序
4、内存没有问题的话就要去看磁盘了，磁盘我用iostat去查看，我遇到的磁盘问题比较少
5、还有就是带宽问题，一般会用iftop去查看流量情况，看看流量是否超过的机器给定的带宽
6、涉及到具体应用的话，就要根据具体应用的设定参数来查看，比如连接数是否查过设定值等
7、如果系统层各个指标查下来都没有发现异常，那么就要考虑外部系统了，比如数据库、缓存、存储等

性能指标的评判有以上二种常用的角度
接着六步
1.选择性能指标评估应用和系统的性能
2.为应用和系统设定性能目标
3.进行性能基准测试
4.性能分析定位瓶颈
5.优化系统和应用程序
6.性能监控和告警


Linux的性能调优问题往往是涉及很多其他服务性能调优问题。
运维经常接触的：
nginx/haproxy性能调优
数据库oracle mysql的性能调优
kafka队列的性能调优
redis/memcache缓存的性能调优

然后就是具体应用层面的
java JVM服务性能调优
python 服务性能调优

希望讲师可以围绕实际的这些案例去展开。
在我工作中所遇到的 其实就是服务在linux上面跑出现了“性能瓶颈”？
涉及性能的无外乎在linux的表象就是 CPU高了 内存占用高了 磁盘IO高了 网卡流量高了。
以Nginx为例每一个高并发 高吞吐量 低延迟要求的服务都需要linux配合个性化配置柏阔内核参数 基于操作系统配置调整相关服务参数 根据使用场景配置相关参数以达到——以较低的物理机资源实现较高的业务吞吐量并维持低延迟的目标
工作中一般涉及到性能优化的两个触发点：
1 性能突然恶化（CPU 内存 磁盘 网卡）排查解决问题
2 压测想提高单节点吞吐量 应对大促、成本优化、业务增长带来的对资源的需求。
